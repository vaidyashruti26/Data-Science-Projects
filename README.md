# Pandas
 
    Practiced following topics in Pandas -
    1  Creation of Series and DataFrame
    2  Indexing & slicing in DataFrame
    3  Creation of New column
    4  pop, del & insert function
    5  loading csv file in DF using pd.read_csv
    6  checking different statistical paramerters like mean ,median, min , max, standard deviation etc
    7  filter dataframe
    8  any & all functions
    9  checking Null vales in column & drop them using dropna function
    10  plotting different graph like Histogram, bar graph etc
    11  Groupby function
    12  merging of 2 DF using Merge function
    13  convering timestamp column to time using pd.to_datetime function

# Numpy
    Practiced following topics in Numpy -
    1  defined 1 & 2 dimensional arrays
    2  checking shape of array & reshape it using np.reshape function
    3  replacing specific element in the array
    4  checked different functions like np.zeros , ones, full, eye etc
    5  created array with random values using np.random.rand function
    6  Indexing & slicing in array
    7  filtering in array
    8  changing DataType of array elements
    9  Arithmetic operartions on array like addtion, subtraction, multiplication, division , squareroot etc
    10  Arithmetic operartions on array like mean, median etc
    11  sorting of array elements in ascending or desending order
    12  finding unique elements using np.unique funtion
    13  use of different functions like union1d, intersect1d , setdiff1d etc
    14  adding rows or column in existing array
    15  Performed speed test on list & array - Conclusion - Array operations are faster than list (it consumes less time & memory)
    16  checked dot product of 2 arrays
    17  checked maximum & where function
    18  merging of 2 arrays using vstack , hstack, & concatenate functions

# Visualization_Matplotlib
    Practiced following topics in Matplotlib -
    1  Importing various python libraries.
    2  Data visualsation using head() and shape functions.
    3  Column operations using unique() and tolist() functions.
    4  Data visualisation using Matplotlib. Plotted basic bar graphs.
    5  Data visualisation using line graph.
    6  Data exploration and visualisation using hist graph.
    7  Data visualisation using subplotting.
    8  Data visualisation using scatterplot.
   
# Data Extraction from SQLITE Database
    Practiced following topics -
    1. Importing various python libraries.
    2. Creation of connection with SQLITE database.
    3. Read SQL query.
    4. data visualisation using head() function.
    5. Data processing by checking null values. There are null values it has removed by dropna() function.
    6. Visualisation of values such as count, min, max, standard deviation, mean of the data by using describe() function.
    7. To see correlation between columns in the dataset I used corr() function.
    8. Splitted data into train and test.
    9. Train the model using LinearRegression classification algorithm.
    10. Determined accuracy of the model.

#  Honey Production Dataset Analysis
    Practiced following topics-
    1. Importing pandas, numpy, matplotlib,seaborn python libraries.
    2. Read honey production dataset.
    3. Visualise total record number using shape and head function.
    4. Visualisation of values such as count, min, max, standard deviation, mean of the data by using describe() function.
    5. Created summary table to understand the trend using year variable and visualisation of that column.
    6. Visualising the trend of Yield per Colony from year 1998 to 2012.
    7. Visualising the total honey production from the year 1998 to 2012.
    8. Group the dataset by states and using sum method to get the total honey product.
    9. Created a Bar chart to visualize the total honey production by states.
    10. Created a table to find out maximum production value from the states.
    11. Created a table to find out minimum production value from the states.
    12. Merging the Max Prod and Min Prod varible to find the range.
    13. Created a Bar chart to visualize the statewise decline trend.
    14. Checked the correlation between variables.
    15. Visualised the same in Heatmap().
    16. Checked hypothesis: "More the number of colonies, higher the production value.
    17. Splitted data into train and test.
    18. Train the model using LinearRegression classification algorithm.
    19. Determined accuracy of the model.
  
#  Titanic Data Exploration Using Logistic Regression
    Practiced following topics-
    1. Importing various python libraries.
    2. Importing dataset and visualisation of data by using head() and shape function.
    3. Data Processing by checking null values. There are null values in dataset. filled nullvalues using sum() function. The function will fill the null values by counting sum of the column values.
    4. drawn a bar plot of survival by sex.
    5. print percentages of females vs. males that survive.
    6. draw a bar plot of survival by Pclass.
    7. print percentage of people by Pclass that survived.
    8. Visualisation of values such as count, min, max, standard deviation, mean of the data by using describe() function.
    9. New column created. calculate percentages of new column vs.already present column.
    10. Drawn a bar plot of CabinBool vs. survival columns.
    11. Drop the null values from the dataset.
    12. Imported libraries regarding Logistic Regression.
    13. Dropped the columns whose values are categorical. Replaced particular column data type to another data type.
    14. Splitted data into train and test.
    15. Train the model using LogisticRegression classification algorithm.
    16. Determined accuracy of the model.
    17. Confusion matrix calculated.

#  Iris Data Exploration Using KNN
    practiced following points - 
    1. Importing various python libraries.
    2. Importing dataset and visualisation of data by using head() and shape function.
    3. Data view by head() and shape function. There are 150 rows and 6 columns.
    4. Data exploration by finding column names, changing column names.
    5. Data description using description function().
    6. Data Processing by checking null values. There are no null values are present in dataset.
    7. Used value_counts() function on target column to see the kind of species.
    8. Scatter plot of two columns.
    9. Bar graph plotting on four columns.
    10. To visualise more details plotted scatter plot.
    11. To visualise the data in various angles used pair plots.
    12. Box-plot for visualized  of description of the data.
    13. Violen plot to visualise the data into different format.
    14. Dispaly correlation between data columns.
    15. Display correlation matrix.
    16. Importing SnadardScaler and done Model training using KNN algorithm.
    17. Found accuracy of KNN algorithm and display confusion matrix.
    18. Applied Logistic regression algorithm on dataset to compare between KNN algorithm accuracy and Logistic regression.

#  House Prediction in King Country USA
       practiced following points - 
       1. Imported various python libraries.
       2. Imported dataset and visualisation of data by using head() and shape function. There are 21613 rows and 21 columns in the dataset.
       3. Exploratory data analysis is done by using describe(), info(), isnull().sum() functions.
       4. Ploted Boxplot to see prices of bedrooms.
       5. Ploted distplot on price column.
       6. Splitted data into training and testing.
       7. 75% of data I used for training. as well as 25% for testing.
       8. Normalisation basically standardization of the data is done.
       9. Model training is done by using Linear Regression algorithm.
       10. Mean absolute error is displayed.
       11. Prediction for single house is done.
#   Store Analysis Using Linear Model
       practiced following points - 
       1. Imported various python libraries.
       2. Imported 5 datasets(store, train. test, sample_submission, features) and visualisation of data by using head() and shape function.
       3. Visualising data using bar graphs.
       4. merging two datasets.
       5. Splitting data into train and test.
       6. Applied Linear regression model.
#  Covid-19 Data Analysis
        In this Data analysis I analysed the data of covid-19 infection all over the world from jan 2020. It includes data analysis using map, bar graphs and scatter plots.
